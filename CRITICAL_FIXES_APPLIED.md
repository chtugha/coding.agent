# Critical Fixes Applied - 2025-10-14

## Summary

Fixed TWO critical issues based on detailed log analysis:

1. **üêõ NO AUDIO HEARD** - Added logging to diagnose why only 13 audio frames were sent (260ms) instead of full responses
2. **‚úÇÔ∏è VAD CUTTING TOO EARLY** - Increased threshold from 0.05 to 0.10 to prevent fragmentation

---

## Issue #1: No Audio Heard - Root Cause Investigation

### Evidence from Logs

**Exit Statistics**:
```
Outbound stream thread exiting (sent 13 audio frames, 1207 silence frames, 1220 total)
```

**ONLY 13 AUDIO FRAMES!** That's only 260ms of audio (13 √ó 20ms).

**But Kokoro generated MUCH more**:
```
t1: LLaMA send-to-Kokoro [call 141] ts=1760428460.929291
‚è±Ô∏è  Kokoro pipeline first audio: 367.1ms
t2: Kokoro first subchunk sent [call 141] ts=1760428461.296606
t3: First RTP frame sent [call 141] ts=1760428461.301
```

And there were 3 more responses after this!

### The Problem

The logs show:
1. ‚úÖ Kokoro synthesizes audio (4 responses total)
2. ‚úÖ Outbound processor receives audio ("t2" logged)
3. ‚úÖ Outbound processor writes to SHM ("t3" logged)
4. ‚ùå SIP client sends ONLY 13 audio frames (should be hundreds!)

**Hypothesis**: The outbound processor is writing audio to `out_buffer_`, but the SIP client is reading SILENCE (all 0xFF) from SHM instead of the actual audio data.

**Possible causes**:
1. Audio is not being added to `out_buffer_` correctly
2. Audio is being added but immediately dropped (buffer full)
3. Audio is being added but SHM write is failing
4. SHM write succeeds but SIP client reads stale/wrong data

### Changes Made

**File**: `outbound-audio-processor.cpp`

**1. Enhanced enqueue_g711_ Logging** (lines 301-326):
```cpp
static int enqueue_count = 0;
size_t before_size = out_buffer_.size();
out_buffer_.insert(out_buffer_.end(), g711.begin(), g711.begin() + to_copy);
if (++enqueue_count <= 5 || enqueue_count % 50 == 0) {
    std::cout << "üì• Enqueued " << to_copy << " bytes to out_buffer (was " << before_size << ", now " << out_buffer_.size() << ")" << std::endl;
}
```

**2. Buffer Full Logging** (lines 310-314):
```cpp
if (capacity == 0) {
    static int drop_count = 0;
    if (++drop_count <= 3 || drop_count % 50 == 0) {
        std::cout << "‚ö†Ô∏è  Dropping " << g711.size() << " bytes (buffer full: " << out_buffer_.size() << " bytes)" << std::endl;
    }
    return;
}
```

**3. Enhanced t3 Logging** (line 390):
```cpp
std::cout << "t3: First RTP frame sent [call " << call_id << "] ts=" << ms << " (buffer had " << buffer_size << " bytes)" << std::endl;
```

### Expected New Logs

**If audio IS being enqueued**:
```
‚è±Ô∏è  Kokoro pipeline first audio: 367ms
t2: Kokoro first subchunk sent [call 141] ts=...
üì• Enqueued 320 bytes to out_buffer (was 0, now 320)  ‚Üê NEW!
üì• Enqueued 320 bytes to out_buffer (was 320, now 640)  ‚Üê NEW!
t3: First RTP frame sent [call 141] ts=... (buffer had 640 bytes)  ‚Üê NEW!
üé§ Started sending AUDIO frames (was silence) on port 10001
üîä Sent audio frame #1 (160 bytes) on port 10001
```

**If audio is NOT being enqueued**:
```
‚è±Ô∏è  Kokoro pipeline first audio: 367ms
t2: Kokoro first subchunk sent [call 141] ts=...
[NO "üì• Enqueued" messages!]  ‚Üê PROBLEM!
t3: First RTP frame sent [call 141] ts=... (buffer had 0 bytes)  ‚Üê PROBLEM!
[NO "üé§ Started sending AUDIO frames" message!]
```

**If buffer is full**:
```
üì• Enqueued 320 bytes to out_buffer (was 0, now 320)
üì• Enqueued 320 bytes to out_buffer (was 320, now 640)
...
‚ö†Ô∏è  Dropping 320 bytes (buffer full: 1600 bytes)  ‚Üê PROBLEM!
```

---

## Issue #2: VAD Cutting Sentences Too Early

### Evidence from Logs

User said: **"I don't hear anything"**

But VAD cut it into:
```
üì¶ Chunk created (max_size): 16000 samples (~1.00 s), meanRMS=0.10
üìù [141] Transcription:  I don't...

üì¶ Chunk created (max_size): 16000 samples (~1.00 s), meanRMS=0.08
üìù [141] Transcription:  year.
```

Whisper transcribed it as: **"I don't... year."** instead of **"I don't hear anything"**

### Root Cause

**VAD threshold was 0.05**, giving:
- `vad_stop_threshold = 0.025` (0.05 √ó 0.5)
- User's speech RMS: 0.08-0.10
- Silence RMS: < 0.03

The user's speech (0.08-0.10) is ALWAYS above the stop threshold (0.025), so VAD never detects silence DURING speech. It only stops when hitting the 1.0s max_size limit.

**Result**: Every chunk is 1.0s (max_size), cutting sentences mid-word.

### The Fix

**File**: `simple-audio-processor.cpp` (line 86)

**Changed threshold from 0.05 to 0.10**:
```cpp
chunk_duration_ms_(1000), vad_threshold_(0.10f), silence_timeout_ms_(500), database_(nullptr) {
```

**New thresholds**:
- `vad_threshold_ = 0.10`
- `vad_stop_threshold = 0.05` (0.10 √ó 0.5)
- `vad_start_threshold = 0.15` (0.10 √ó 1.5)

**User's speech RMS**: 0.08-0.10
**Silence RMS**: < 0.03

Now:
- Speech (0.08-0.10) is ABOVE stop threshold (0.05) ‚Üí VAD detects as speech ‚úÖ
- Silence (< 0.03) is BELOW stop threshold (0.05) ‚Üí VAD detects as silence ‚úÖ
- Pauses between words (0.03-0.05) will trigger speech end ‚úÖ

### Expected Result

**Before** (threshold=0.05):
```
üì¶ Chunk created (max_size): 16000 samples (~1.00 s), meanRMS=0.10
üìù Transcription:  I don't...
üì¶ Chunk created (max_size): 16000 samples (~1.00 s), meanRMS=0.08
üìù Transcription:  year.
```

**After** (threshold=0.10):
```
üì¶ Chunk created (end_of_speech): 11200 samples (~0.70 s), meanRMS=0.09
üìù Transcription:  I don't hear anything.
```

Complete sentence in ONE chunk!

---

## Testing Instructions

### 1. Restart Services

**CRITICAL**: You MUST restart services to load new binaries:
```bash
cd /Users/whisper/Documents/augment-projects/clean-repo
pkill -f "sip-client|llama-service|whisper-service|kokoro|http-server|inbound-audio|outbound-audio"
./start-wildfire.sh
```

### 2. Make Test Call

Place a call and:
1. Say "Hello" (short utterance)
2. Wait for response
3. Say "I don't hear anything" (longer utterance with pause)
4. Wait for response
5. Hang up

### 3. Check Logs

**For Issue #1 (No Audio)**:

Look for these NEW logs:
```
üì• Enqueued X bytes to out_buffer (was Y, now Z)
t3: First RTP frame sent [call X] ts=... (buffer had Z bytes)
üé§ Started sending AUDIO frames (was silence) on port 10001
```

**Diagnosis**:
- **If you see "üì• Enqueued"**: Audio IS being added to buffer ‚úÖ
- **If you DON'T see it**: Audio is NOT being added (conversion failing) ‚ùå
- **If you see "‚ö†Ô∏è  Dropping"**: Buffer is full (shouldn't happen with 200ms cap) ‚ö†Ô∏è
- **If buffer had 0 bytes at t3**: No audio in buffer when SHM write happened ‚ùå
- **If you see "üé§ Started sending AUDIO"**: SIP client IS reading audio from SHM ‚úÖ

**For Issue #2 (VAD)**:

Look for:
```
üì¶ Chunk created (end_of_speech): X samples (~Y s), meanRMS=Z
```

**Diagnosis**:
- **If most chunks are "end_of_speech"**: VAD is working correctly ‚úÖ
- **If most chunks are "max_size"**: VAD threshold still too low ‚ùå

### 4. Final Statistics

At call end, check:
```
Outbound stream thread exiting (sent X audio frames, Y silence frames, Z total)
```

**Expected**:
- Audio frames: 200-400 (4-8 seconds of speech)
- Silence frames: 800-1000 (16-20 seconds of silence)
- Total: ~1200 (24 seconds call)

**If audio frames < 50**: Audio pipeline is broken!

---

## Diagnosis Flow

### If You Still Hear No Audio

**Step 1**: Check if audio is being enqueued
```
üì• Enqueued X bytes to out_buffer
```
- **YES**: Go to Step 2
- **NO**: Audio conversion is failing (Kokoro ‚Üí G.711)

**Step 2**: Check if buffer has audio at t3
```
t3: First RTP frame sent [call X] ts=... (buffer had Z bytes)
```
- **Z > 0**: Go to Step 3
- **Z = 0**: Timing issue (SHM write before audio arrives)

**Step 3**: Check if SIP client reads audio
```
üé§ Started sending AUDIO frames (was silence) on port 10001
```
- **YES**: Audio IS being sent! Problem is codec/network/phone
- **NO**: SHM communication broken (write succeeds but read fails)

**Step 4**: Check final statistics
```
Outbound stream thread exiting (sent X audio frames, ...)
```
- **X > 100**: Audio was sent, problem is external
- **X < 50**: Audio pipeline is broken

### If VAD Still Cuts Too Early

**Check chunk logs**:
```
üì¶ Chunk created (max_size): 16000 samples (~1.00 s), meanRMS=X
```

If you still see mostly "max_size" chunks:
- **meanRMS > 0.05**: Threshold needs to be even higher (try 0.15)
- **meanRMS < 0.05**: Threshold is correct, but user is speaking continuously for >1s

---

## Technical Details

### Audio Buffer Flow

```
Kokoro (24kHz float32)
  ‚Üì TCP subchunks (40ms each)
Conversion Worker Thread
  ‚Üì Resample 24kHz ‚Üí 8kHz
  ‚Üì Convert float32 ‚Üí G.711 Œº-law
  ‚Üì enqueue_g711_() ‚Üí out_buffer_
RTP Scheduler Thread (20ms loop)
  ‚Üì Read 160 bytes from out_buffer_
  ‚Üì Write to SHM (/ap_out_X)
SIP Client Outbound Thread (20ms loop)
  ‚Üì Read 160 bytes from SHM
  ‚Üì Check if audio (not all 0xFF)
  ‚Üì Send as RTP packet
Phone
```

### Buffer Capacity

- **Max buffer size**: 1600 bytes (10 frames √ó 160 bytes = 200ms)
- **Kokoro subchunk**: 40ms @ 24kHz = 960 samples ‚Üí 320 samples @ 8kHz = 320 bytes
- **RTP frame**: 20ms @ 8kHz = 160 samples = 160 bytes

So each Kokoro subchunk (40ms) produces 2 RTP frames (2 √ó 20ms).

### VAD Threshold Calculation

- **Threshold**: 0.10
- **Start threshold**: 0.15 (1.5√ó threshold)
- **Stop threshold**: 0.05 (0.5√ó threshold)
- **Hangover**: 400ms (wait after RMS drops below stop threshold)
- **Max chunk**: 1.0s (force send if speech continues too long)

**Speech detection**:
1. RMS rises above 0.15 ‚Üí speech starts
2. RMS stays above 0.05 ‚Üí speech continues
3. RMS drops below 0.05 for 400ms ‚Üí speech ends

---

## Summary

**Issue #1: No Audio** - Added comprehensive logging to trace audio flow from Kokoro to RTP
- Will show if audio is being enqueued to buffer
- Will show if buffer has audio when writing to SHM
- Will show if SIP client is reading audio from SHM

**Issue #2: VAD Cutting** - Increased threshold from 0.05 to 0.10
- Stop threshold now 0.05 (was 0.025)
- Should properly detect pauses between words
- Should produce complete sentences in single chunks

**All changes compiled successfully.**
**Services MUST be restarted to take effect.**

After restart, make a test call and share the logs. The new logging will definitively show where the audio pipeline is breaking.

